{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc8586-ce23-42e2-a6ff-666b5c42fcef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b584d-c66c-431b-92ca-adb7a3b12bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33c2f7-4ba0-49ff-a3df-7e769dbb7f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llm.google import gemini_flash\n",
    "from llm.google import gemini_pro\n",
    "from llm.google import gemini_flash_json\n",
    "from llm.groq import llama3 as groq_lllama3\n",
    "\n",
    "import log_manager\n",
    "from utils import vertex_ai_utils\n",
    "from graph import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e67bc-371b-48ce-be76-491cb082a634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    List a few popular cookie recipes using this JSON schema:\n",
    "    Recipe = {\"recipe_name\": str}\n",
    "    Return: list[Recipe]\n",
    "  \"\"\"\n",
    "response = gemini_flash_json.invoke(prompt)\n",
    "# print(response.content)\n",
    "y = json.loads(response.content)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbdcc77-8c9c-4ff1-ac81-7ef75e2539f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from graph.failure_analysis import failure_analysis_graph\n",
    "utils.display_graph(failure_analysis_graph)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2723aa8-e8e4-45c3-b0ac-e2292640d4fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "job_states = [\"JOB_STATE_FAILED\"]\n",
    "\n",
    "# pipeline_run_name = \"fab-10-orion-kbl-analytics-pipeline-batch-2407092015\"\n",
    "# pipeline_run_name = 'fab-10-orion-kbl-analytics-pipeline-batch-2405290940'\n",
    "# pipeline_run_name = 'fab-7-orion-kbl-analytics-pipeline-batch-2407161945' # success job\n",
    "# pipeline_run_name = 'fab-7-orion-kbl-analytics-pipeline-batch-2407162000'\n",
    "\n",
    "# pipeline_run_name = 'fab-10-orion-kbl-analytics-pipeline-batch-2406201505'\n",
    "pipeline_run_name = \"fab-7-orion-kbl-analytics-pipeline-batch-2406191525\"\n",
    "\n",
    "\n",
    "\n",
    "custom_job_id_list = vertex_ai_utils.get_custom_job_id_list(pipeline_run_name = pipeline_run_name,\n",
    "                                                            job_states = job_states)\n",
    "\n",
    "print(custom_job_id_list)\n",
    "custom_job_id_count = len(custom_job_id_list)\n",
    "custom_job_id_index = 0\n",
    "\n",
    "state = {\"custom_job_id_list\":custom_job_id_list, \n",
    "         \"custom_job_id_count\":custom_job_id_count,\n",
    "         \"custom_job_id_index\":custom_job_id_index,\n",
    "        }\n",
    "\n",
    "state = failure_analysis_graph.invoke(state)\n",
    "\n",
    "failure_analysis_reports = state['failure_analysis_report']\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------failure_analysis_issues---------------------------------\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "if len(failure_analysis_reports) > 0:\n",
    "    print(len(failure_analysis_reports))\n",
    "    for failure_analysis_report in failure_analysis_reports: \n",
    "        print('-------------')\n",
    "        print(failure_analysis_report.issues_exist)\n",
    "        print(failure_analysis_report.issues)\n",
    "else:\n",
    "    print('no-issues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e630e4c-0e9e-44ea-8d39-ed2b18b317ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from graph import utils\n",
    "from graph.log_analyser import log_analyser_app\n",
    "utils.display_graph(log_analyser_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbb5d5-642d-43c3-a8d6-25bad721f596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# job_states = [\"JOB_STATE_FAILED\", \"JOB_STATE_SUCCEEDED\"]\n",
    "job_states = [\"JOB_STATE_FAILED\"]\n",
    "\n",
    "pipeline_run_name = 'fab-10-orion-kbl-analytics-pipeline-batch-2407251025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81db1187-ad93-423d-aee8-eba8582c99e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "**collect_custom_jobs** working...\n",
      "pipeline_run_name:fab-10-orion-kbl-analytics-pipeline-batch-2407251025\n",
      "custom_job_id_list:['84469431048077312', '6310695915887788032', '6058494336755040256', '1699009897460400128', '1446808318327652352', '793786372358930432', '4110687497917300736', '6842120671917506560', '4536277662703812608', '6360235511788863488', '3455413752134893568']\n",
      "custom_job_id_index:0\n",
      "**invoke_failure_analysis**...\n",
      "----------------------------------------\n",
      "**check_log_issues** working...\n",
      "job_id:84469431048077312\n",
      "You are a experienced in Application Log Analyser.\n",
      "Each log entries are ordered in sequencial manner.\n",
      "You will be provided the log entries by triple backticks\n",
      "```\n",
      "## Log Entries:\n",
      "\u001b[38;20m2024-07-25 10:33:13,936 - INFO | project_id: gdw-dev-orion-streaming\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,957 - INFO | fab_name: fab-10\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | pipeline_name: orion-kbl-analytics-pipeline\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | batch_id: 2407251025\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | partition_id: 4\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | job_id_list: [2407251025004]\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | BatchAnalysisRunner initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,958 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|job_id list:2407251025004\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,960 - INFO | initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,960 - INFO | AnalyticsKblBatchJob initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,961 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|BatchAnalysisRunner runninig analytics job in parallel\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,961 - INFO | Ray initialized for parallel run now\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:13,962 - INFO | Ray utilized cpu count: 4\u001b[0m\n",
      "2024-07-25 02:33:16,079\tINFO services.py:1914 -- object_store_memory is not verified when plasma_directory is set.\n",
      "2024-07-25 02:33:17,346\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "\u001b[38;20m2024-07-25 10:33:20,124 - INFO | BigQuery: Processed data size: --26.18 MB.--\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,127 - INFO | fab-10|2407251025004- Analytics_Job: Configuration execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,505 - INFO | fab-10|2407251025004- Analytics_Job: Configuration execution completed successfully\u001b[0m\n",
      "[\"KeyError: 'num_incoming_steps'\"]\n",
      "\u001b[38;20m2024-07-25 10:33:20,506 - INFO | Batch_id:2407251025 update_status_by_batch_id: execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,506 - INFO | Batch_id:2407251025 update_batch_status_by_batch_id: execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,506 - INFO | initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,506 - INFO | AnalyticsKblBatchJobTrigger initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,507 - INFO | AnalyticsKblBatchJobTrigger:update_batch_status_by_batch_id execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:20,507 - INFO | \n",
      "        UPDATE gdw-dev-orion-streaming.fab_10_orion.ecap_analytics_kbl_batch_job_trigger\n",
      "        SET \n",
      "        batch_status = 'failed',\n",
      "        updated_time = CURRENT_TIMESTAMP()\n",
      "        ,batch_remarks = 'KeyError : num_incoming_steps'\n",
      "        WHERE \n",
      "        batch_id = 2407251025\n",
      "        \u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:36,413 - DEBUG | Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_common_lib/bq_utils.py\", line 60, in biqquery_job_executor\n",
      "    query_job.result()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1520, in result\n",
      "    do_get_result()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
      "    _retry_error_helper(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
      "    raise final_exc from source_exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
      "    result = target()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1510, in do_get_result\n",
      "    super(QueryJob, self).result(retry=retry, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py\", line 922, in result\n",
      "    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/google/api_core/future/polling.py\", line 261, in result\n",
      "    raise self._exception\n",
      "google.api_core.exceptions.BadRequest: 400 Could not serialize access to table gdw-dev-orion-streaming:fab_10_orion.ecap_analytics_kbl_batch_job_trigger due to concurrent update\n",
      "\n",
      "Location: US\n",
      "Job ID: dde0e7ae-540c-4a02-afcb-7ecc5fa56452\n",
      "\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmp.cgRavQVESW\", line 74, in <module>\n",
      "    _outputs = execute(**_parsed_args)\n",
      "  File \"/tmp/tmp.cgRavQVESW\", line 49, in execute\n",
      "    BatchJobManager.update_status_by_batch_id(project_id =project_id,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/components/batch_job_manager.py\", line 174, in update_status_by_batch_id\n",
      "    BatchJobManager.update_batch_status_by_batch_id(project_id =project_id,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/components/batch_job_manager.py\", line 159, in update_batch_status_by_batch_id\n",
      "    analytics_kbl_batch_job_trigger.update_batch_status_by_batch_id(batch_status = batch_status,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/data/analytics_kbl_batch_job_trigger.py\", line 73, in update_batch_status_by_batch_id\n",
      "    self.bigquery_manager.biqquery_job_executor(query_string)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_common_lib/bigquery_manager.py\", line 79, in biqquery_job_executor\n",
      "    return bq_utils.biqquery_job_executor(project_id = self.project_id,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_common_lib/bq_utils.py\", line 70, in biqquery_job_executor\n",
      "    raise exception \n",
      "```\n",
      "Ignore any warnings and any deprecated messages from log entries\n",
      "Give a binary score 'yes' or 'no' score only to indicate whether log entries have issues/exception/error\n",
      "\n",
      "---**response**--:\n",
      "issues_exist:True\n",
      "----------------------------------------\n",
      "**find_log_issues** working...\n",
      "----------------------------------------\n",
      "**find_log_exception** working...\n",
      "----------------------------------------\n",
      "**check_log_issues** working...\n",
      "job_id:6310695915887788032\n",
      "You are a experienced in Application Log Analyser.\n",
      "Each log entries are ordered in sequencial manner.\n",
      "You will be provided the log entries by triple backticks\n",
      "```\n",
      "## Log Entries:\n",
      "\u001b[38;20m2024-07-25 10:33:10,705 - INFO | project_id: gdw-dev-orion-streaming\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | fab_name: fab-10\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | pipeline_name: orion-kbl-analytics-pipeline\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | batch_id: 2407251025\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | partition_id: 3\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | job_id_list: [2407251025003]\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,727 - INFO | BatchAnalysisRunner initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,728 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,728 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|job_id list:2407251025003\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,730 - INFO | initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,730 - INFO | AnalyticsKblBatchJob initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,730 - INFO | orion-kbl-analytics-pipeline|fab-10|2407251025|BatchAnalysisRunner|BatchAnalysisRunner runninig analytics job in parallel\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,731 - INFO | Ray initialized for parallel run now\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:10,732 - INFO | Ray utilized cpu count: 4\u001b[0m\n",
      "2024-07-25 02:33:12,838\tINFO services.py:1914 -- object_store_memory is not verified when plasma_directory is set.\n",
      "2024-07-25 02:33:14,104\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "\u001b[38;20m2024-07-25 10:33:17,019 - INFO | BigQuery: Processed data size: --26.18 MB.--\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,021 - INFO | fab-10|2407251025003- Analytics_Job: Configuration execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,315 - INFO | fab-10|2407251025003- Analytics_Job: Configuration execution completed successfully\u001b[0m\n",
      "[\"KeyError: 'num_incoming_steps'\"]\n",
      "\u001b[38;20m2024-07-25 10:33:17,316 - INFO | Batch_id:2407251025 update_status_by_batch_id: execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,316 - INFO | Batch_id:2407251025 update_batch_status_by_batch_id: execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,316 - INFO | initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,317 - INFO | AnalyticsKblBatchJobTrigger initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,317 - INFO | AnalyticsKblBatchJobTrigger:update_batch_status_by_batch_id execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:17,317 - INFO | \n",
      "        UPDATE gdw-dev-orion-streaming.fab_10_orion.ecap_analytics_kbl_batch_job_trigger\n",
      "        SET \n",
      "        batch_status = 'failed',\n",
      "        updated_time = CURRENT_TIMESTAMP()\n",
      "        ,batch_remarks = 'KeyError : num_incoming_steps'\n",
      "        WHERE \n",
      "        batch_id = 2407251025\n",
      "        \u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,892 - INFO | BigQuery: Processed data size: --1.85 MB.--\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,893 - INFO | AnalyticsKblBatchJobTrigger:update_batch_status_by_batch_id execution completed\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,893 - INFO | Batch_id:2407251025 update_batch_status_by_batch_id: execution completed successfully\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,893 - INFO | Batch_id:2407251025 update_job_status_by_batch_id: execution started\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,893 - INFO | initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:22,893 - INFO | AnalyticsKblBatchJob initialized\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:27,050 - INFO | BigQuery: Processed data size: --51.9 MB.--\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:27,050 - INFO | Batch_id:2407251025 update_job_status_by_batch_id: execution completed successfully\u001b[0m\n",
      "\u001b[38;20m2024-07-25 10:33:27,050 - INFO | Batch_id:2407251025 update_status_by_batch_id: execution completed successfully\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmp.BglpxzOt3a\", line 38, in execute\n",
      "    batch_analysis_runner.execute(partition_id =partition_id,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/components/batch_analysis_runner.py\", line 43, in execute\n",
      "    batch_job_manager.run_analysis_batch_job_parallel(job_id_list = job_id_list)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/components/batch_job_manager.py\", line 87, in run_analysis_batch_job_parallel\n",
      "    job_input_list = self.analytics_kbl_batch_job.get_job_input_list(job_id_list =job_id_list)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_pipeline_lib/data/analytics_kbl_batch_job.py\", line 84, in get_job_input_list\n",
      "    job_input = JobInput(project_id = self.project_id,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/orion_kbl_analytics_lib/analytics/job_input.py\", line 67, in __init__\n",
      "    self.num_incoming_steps = self.config['num_incoming_steps']\n",
      "KeyError: 'num_incoming_steps'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "  File \"/tmp/tmp.BglpxzOt3a\", line 74, in <module>\n",
      "    _outputs = execute(**_parsed_args)\n",
      "  File \"/tmp/tmp.BglpxzOt3a\", line 58, in execute\n",
      "    raise Exception(f\"Error occured in '{COMPONENT_NAME}'. Inner_Exception:'{e}'.\")  \n",
      "Exception: Error occured in 'BatchJobsRunner'. Inner_Exception:''num_incoming_steps''. \n",
      "```\n",
      "Ignore any warnings and any deprecated messages from log entries\n",
      "Give a binary score 'yes' or 'no' score only to indicate whether log entries have issues/exception/error\n",
      "\n",
      "---**response**--:\n",
      "issues_exist:True\n",
      "----------------------------------------\n",
      "**find_log_issues** working...\n",
      "----------------------------------------\n",
      "**find_log_exception** working...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m}\n\u001b[1;32m      2\u001b[0m state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_run_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:pipeline_run_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_states\u001b[39m\u001b[38;5;124m\"\u001b[39m:job_states}\n\u001b[0;32m----> 3\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mlog_analyser_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreport_generation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1691\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1690\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1691\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1693\u001b[0m     config,\n\u001b[1;32m   1694\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1695\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1696\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m   1697\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1698\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1699\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1701\u001b[0m ):\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1703\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1070\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     done, inflight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(), \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m futures:\n\u001b[0;32m-> 1070\u001b[0m     done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[1;32m   1080\u001b[0m         task \u001b[38;5;241m=\u001b[39m futures\u001b[38;5;241m.\u001b[39mpop(fut)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 200}\n",
    "state = {\"pipeline_run_name\":pipeline_run_name, \"job_states\":job_states}\n",
    "state = log_analyser_app.invoke(state, config=config)\n",
    "print(state['report_generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b9cbd-218c-49a9-944d-77ea1b7c4203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc67ec8-107b-4a2f-917b-b6be229e21d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43ad79-66b0-41ab-b554-6e1aef04ee08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eef0c8-4f61-4db5-b607-80ee0e4be674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-8:m120"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
